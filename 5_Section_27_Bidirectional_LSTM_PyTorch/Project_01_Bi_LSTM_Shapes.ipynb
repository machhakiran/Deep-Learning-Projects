{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"j7-LiwqUMGYL","executionInfo":{"status":"ok","timestamp":1718747302307,"user_tz":240,"elapsed":4130,"user":{"displayName":"zeeshan ahmad","userId":"09790783261567949831"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"xxH9iWl34bmR"},"source":["# Input Parameters of Bidirectional LSTM"]},{"cell_type":"markdown","source":["***nn.LSTM( input_size, hidden_size, num_layers, batch_first = True, bidirectional = True )***"],"metadata":{"id":"3rWGnQulkIXg"}},{"cell_type":"markdown","source":["***input_size = The number of expected features in the input. Feature dimension***\n","\n","***hidden_size = Number of units in the hidden state. The number of features in the hidden state h***\n","\n","***num_layers = Number of vertical stacks of hidden layers***\n","\n","***batch_first = True, it means input shape of the data to the LSTM is (batch_size, seq_len, features)***\n","\n","*** bidirectional = True, it menas that LSTM is bidirectional***"],"metadata":{"id":"_wN_ayfLl5G5"}},{"cell_type":"code","source":[],"metadata":{"id":"ou6EH1BvkZxZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mX42FzZ4rZ5s"},"source":["# 1 - When batch_first = True."]},{"cell_type":"markdown","source":["### Set the Bidirectional LSTM Parameters"],"metadata":{"id":"FWZv0EAH9xjx"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"zTIEHcqz4e6b","executionInfo":{"status":"ok","timestamp":1718747443700,"user_tz":240,"elapsed":196,"user":{"displayName":"zeeshan ahmad","userId":"09790783261567949831"}}},"outputs":[],"source":["input_size  =  1\n","hidden_size = 16\n","num_layers  =  1"]},{"cell_type":"markdown","source":["### Create the Model"],"metadata":{"id":"AfPm1ZcA99xw"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"psI_dzNsrZ5w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718747445242,"user_tz":240,"elapsed":165,"user":{"displayName":"zeeshan ahmad","userId":"09790783261567949831"}},"outputId":"d794d5d0-6f86-4c9f-aeb7-56913294b97b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LSTM(1, 16, batch_first=True, bidirectional=True)"]},"metadata":{},"execution_count":3}],"source":["Bi_lstmModel = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True, bidirectional = True)\n","Bi_lstmModel"]},{"cell_type":"markdown","source":["### Create the data"],"metadata":{"id":"ukhvYeVD-D1n"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"nPMVY6Em5B7y","executionInfo":{"status":"ok","timestamp":1718747467499,"user_tz":240,"elapsed":286,"user":{"displayName":"zeeshan ahmad","userId":"09790783261567949831"}}},"outputs":[],"source":["seqlength = 5 # sequence length or timesteps\n","batchsize = 4 # Batch size or Number of samples\n","\n","# create some random data\n","X = torch.rand(batchsize, seqlength, input_size) # Because batch_first is true, therefore (N,T,D)\n","                                                 # N = Batch size or Number of samples\n","                                                 # T = sequence length or timesteps\n","                                                 # D = Feature Dimension or Inputsize"]},{"cell_type":"markdown","source":["### Get the output from the model"],"metadata":{"id":"BTpdyD-k-guP"}},{"cell_type":"code","source":["y,(h,c) = Bi_lstmModel(X) #hidden_inputs)\n","\n","print(f'Input shape: {list(X.shape)}')            # Batchsize x seqlen x feature dim  OR N x T x D\n","print(f'Hidden shape: {list(h.shape)}')           # 2 * numlayers x Batchsize x hiddensize\n","print(f'Cell memory shape: {list(c.shape)}')      # 2 * numlayers x Batchsize x hiddensize\n","print(f'Output shape: {list(y.shape)}')           # batchsize x seqlen x 2 * hiddensize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XAjFvEC--frB","executionInfo":{"status":"ok","timestamp":1718747486958,"user_tz":240,"elapsed":429,"user":{"displayName":"zeeshan ahmad","userId":"09790783261567949831"}},"outputId":"6e78ed7b-91f2-4586-a344-103ac59c7828"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: [4, 5, 1]\n","Hidden shape: [2, 4, 16]\n","Cell memory shape: [2, 4, 16]\n","Output shape: [4, 5, 32]\n"]}]},{"cell_type":"markdown","metadata":{"id":"iOK5iLqzrZ53"},"source":["# 2- When batch_first = False (default setting)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"OcLep5yPrZ58","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718747609997,"user_tz":240,"elapsed":197,"user":{"displayName":"zeeshan ahmad","userId":"09790783261567949831"}},"outputId":"4cfc77ea-1524-4ae9-82bf-7ecda009fc1d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LSTM(1, 16, bidirectional=True)"]},"metadata":{},"execution_count":6}],"source":["Bi_lstmModel2 = nn.LSTM(input_size, hidden_size, num_layers, bidirectional = True)\n","Bi_lstmModel2"]},{"cell_type":"code","source":["X = torch.rand(seqlength, batchsize, input_size)"],"metadata":{"id":"xEoTACBa_iMv","executionInfo":{"status":"ok","timestamp":1718747614353,"user_tz":240,"elapsed":205,"user":{"displayName":"zeeshan ahmad","userId":"09790783261567949831"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### Get the output from the model"],"metadata":{"id":"gf4dxdWs-3S-"}},{"cell_type":"code","source":["y,(h,c) = Bi_lstmModel2(X) #hidden_inputs)\n","\n","print(f'Input shape: {list(X.shape)}')            # seqlen x Batchsize x feature dim  OR N x T x D\n","print(f'Hidden shape: {list(h.shape)}')           # 2 * numlayers x Batchsize x hiddensize\n","print(f'Cell memory shape: {list(c.shape)}')      # 2 * numlayers x Batchsize x hiddensize\n","print(f'Output shape: {list(y.shape)}')           # seqlen x Batchsize x 2 * hiddensize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Ui4Yso2-6dB","executionInfo":{"status":"ok","timestamp":1718747632868,"user_tz":240,"elapsed":203,"user":{"displayName":"zeeshan ahmad","userId":"09790783261567949831"}},"outputId":"77ddb718-1812-43a8-e647-c9544f27016c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: [5, 4, 1]\n","Hidden shape: [2, 4, 16]\n","Cell memory shape: [2, 4, 16]\n","Output shape: [5, 4, 32]\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"19WUFNKOHKnZ1hEkR6havrl_eIE4BxuaE","timestamp":1635419946139},{"file_id":"1BI9p-vnVoi7Tm8yiQgVN3kpM2VuEzfeE","timestamp":1621245811372},{"file_id":"1o_dLKV6fY7xdZYx_pNMY12zpL_pmMurs","timestamp":1618865813618},{"file_id":"1Q9LtmanyNt675-gO_kXRBKalCdP6xtvV","timestamp":1617253457100},{"file_id":"1jeqKEJfI18GlAhSG8RO5aJ6Vrp4-nkTt","timestamp":1615909315432},{"file_id":"10_geQnah5AvMsm8VDAQwNPhypOXradar","timestamp":1615893340208},{"file_id":"1FtQ99beHYcDFDywLdaPgFm-KjBeI8PvD","timestamp":1615877547147}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}